{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2f0eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-03 23:40:58--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 874188 (854K) [text/plain]\n",
      "Saving to: ‘car_fuel_efficiency.csv’\n",
      "\n",
      "car_fuel_efficiency 100%[===================>] 853.70K  --.-KB/s    in 0.009s  \n",
      "\n",
      "2025-11-03 23:40:58 (95.4 MB/s) - ‘car_fuel_efficiency.csv’ saved [874188/874188]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfee77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('car_fuel_efficiency.csv')\n",
    "\n",
    "# Fill missing values with zeros\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Split the data into train/validation/test sets\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Separate the target variable\n",
    "y_train = df_train['fuel_efficiency_mpg']\n",
    "y_val = df_val['fuel_efficiency_mpg']\n",
    "y_test = df_test['fuel_efficiency_mpg']\n",
    "\n",
    "df_train = df_train.drop(columns=['fuel_efficiency_mpg'])\n",
    "df_val = df_val.drop(columns=['fuel_efficiency_mpg'])\n",
    "df_test = df_test.drop(columns=['fuel_efficiency_mpg'])\n",
    "\n",
    "# Convert dataframes to dictionaries and use DictVectorizer\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "X_val = dv.transform(df_val.to_dict(orient='records'))\n",
    "X_test = dv.transform(df_test.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e344144",
   "metadata": {},
   "source": [
    "# Question 1: Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c8ca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature used for splitting: vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Train a decision tree regressor with max_depth=1\n",
    "dt = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature used for splitting\n",
    "feature_names = dv.get_feature_names_out()\n",
    "split_feature = feature_names[dt.tree_.feature[0]]\n",
    "print(f\"Feature used for splitting: {split_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2e940",
   "metadata": {},
   "source": [
    "# Question 2: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9de19fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.4595777223092726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "# Train a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation dataset\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred,))\n",
    "print(f\"Validation RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e048dd",
   "metadata": {},
   "source": [
    "# Question 3: Experiment with n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbbc30ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=10, RMSE=0.4595777223092726\n",
      "n_estimators=20, RMSE=0.45359067251247054\n",
      "n_estimators=30, RMSE=0.45168672575457125\n",
      "n_estimators=40, RMSE=0.44872083017369974\n",
      "n_estimators=50, RMSE=0.4466568972416094\n",
      "n_estimators=60, RMSE=0.44545970260811213\n",
      "n_estimators=70, RMSE=0.44512632449869965\n",
      "n_estimators=80, RMSE=0.4449843119777284\n",
      "n_estimators=90, RMSE=0.4448614906399875\n",
      "n_estimators=100, RMSE=0.44465186808680424\n",
      "n_estimators=110, RMSE=0.44357876439860233\n",
      "n_estimators=120, RMSE=0.4439118681233817\n",
      "n_estimators=130, RMSE=0.443702590396687\n",
      "n_estimators=140, RMSE=0.4433549955101688\n",
      "n_estimators=150, RMSE=0.44289761494219454\n",
      "n_estimators=160, RMSE=0.4427612219659299\n",
      "n_estimators=170, RMSE=0.44280146504730905\n",
      "n_estimators=180, RMSE=0.44236195357041347\n",
      "n_estimators=190, RMSE=0.4424939711220692\n",
      "n_estimators=200, RMSE=0.4424785084688597\n"
     ]
    }
   ],
   "source": [
    "# Experiment with n_estimators\n",
    "results = []\n",
    "for n in range(10, 201, 10):\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    results.append((n, rmse))\n",
    "\n",
    "# Find the point where RMSE stops improving\n",
    "for n, rmse in results:\n",
    "    print(f\"n_estimators={n}, RMSE={rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a75c78",
   "metadata": {},
   "source": [
    "# Question 4: Best max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf165c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 10\n"
     ]
    }
   ],
   "source": [
    "# Experiment with max_depth and n_estimators\n",
    "depth_results = []\n",
    "for max_depth in [10, 15, 20, 25]:\n",
    "    for n in range(10, 201, 10):\n",
    "        rf = RandomForestRegressor(n_estimators=n, max_depth=max_depth, random_state=1, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        depth_results.append((max_depth, n, rmse))\n",
    "\n",
    "# Find the best max_depth\n",
    "depth_rmse = {}\n",
    "for max_depth, n, rmse in depth_results:\n",
    "    if max_depth not in depth_rmse:\n",
    "        depth_rmse[max_depth] = []\n",
    "    depth_rmse[max_depth].append(rmse)\n",
    "\n",
    "mean_rmse = {k: sum(v) / len(v) for k, v in depth_rmse.items()}\n",
    "best_max_depth = min(mean_rmse, key=mean_rmse.get)\n",
    "print(f\"Best max_depth: {best_max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c54166",
   "metadata": {},
   "source": [
    "# Question 5: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c14bdc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important feature: vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the given parameters\n",
    "rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "importances = rf.feature_importances_\n",
    "feature_importance = sorted(zip(dv.get_feature_names_out(), importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Find the most important feature\n",
    "most_important_feature = feature_importance[0][0]\n",
    "print(f\"Most important feature: {most_important_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b3de7",
   "metadata": {},
   "source": [
    "# Question 6: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b3a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.81393\tval-rmse:1.85444\n",
      "[1]\ttrain-rmse:1.31919\tval-rmse:1.35353\n",
      "[2]\ttrain-rmse:0.98120\tval-rmse:1.01316\n",
      "[3]\ttrain-rmse:0.75443\tval-rmse:0.78667\n",
      "[4]\ttrain-rmse:0.60680\tval-rmse:0.64318\n",
      "[5]\ttrain-rmse:0.51381\tval-rmse:0.55664\n",
      "[6]\ttrain-rmse:0.45470\tval-rmse:0.50321\n",
      "[7]\ttrain-rmse:0.41881\tval-rmse:0.47254\n",
      "[8]\ttrain-rmse:0.39534\tval-rmse:0.45509\n",
      "[9]\ttrain-rmse:0.38038\tval-rmse:0.44564\n",
      "[10]\ttrain-rmse:0.37115\tval-rmse:0.43896\n",
      "[11]\ttrain-rmse:0.36361\tval-rmse:0.43594\n",
      "[12]\ttrain-rmse:0.35850\tval-rmse:0.43558\n",
      "[13]\ttrain-rmse:0.35365\tval-rmse:0.43394\n",
      "[14]\ttrain-rmse:0.35025\tval-rmse:0.43349\n",
      "[15]\ttrain-rmse:0.34666\tval-rmse:0.43362\n",
      "[16]\ttrain-rmse:0.34459\tval-rmse:0.43378\n",
      "[17]\ttrain-rmse:0.34128\tval-rmse:0.43405\n",
      "[18]\ttrain-rmse:0.33822\tval-rmse:0.43391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\ttrain-rmse:0.33709\tval-rmse:0.43374\n",
      "[20]\ttrain-rmse:0.33553\tval-rmse:0.43376\n",
      "[21]\ttrain-rmse:0.33243\tval-rmse:0.43453\n",
      "[22]\ttrain-rmse:0.33031\tval-rmse:0.43510\n",
      "[23]\ttrain-rmse:0.32815\tval-rmse:0.43601\n",
      "[24]\ttrain-rmse:0.32670\tval-rmse:0.43592\n",
      "[0]\ttrain-rmse:2.28944\tval-rmse:2.34561\n",
      "[1]\ttrain-rmse:2.07396\tval-rmse:2.12434\n",
      "[2]\ttrain-rmse:1.88066\tval-rmse:1.92597\n",
      "[3]\ttrain-rmse:1.70730\tval-rmse:1.74987\n",
      "[4]\ttrain-rmse:1.55163\tval-rmse:1.59059\n",
      "[5]\ttrain-rmse:1.41247\tval-rmse:1.44988\n",
      "[6]\ttrain-rmse:1.28796\tval-rmse:1.32329\n",
      "[7]\ttrain-rmse:1.17660\tval-rmse:1.20930\n",
      "[8]\ttrain-rmse:1.07736\tval-rmse:1.10830\n",
      "[9]\ttrain-rmse:0.98883\tval-rmse:1.02009\n",
      "[10]\ttrain-rmse:0.91008\tval-rmse:0.94062\n",
      "[11]\ttrain-rmse:0.84030\tval-rmse:0.87100\n",
      "[12]\ttrain-rmse:0.77874\tval-rmse:0.80916\n",
      "[13]\ttrain-rmse:0.72417\tval-rmse:0.75465\n",
      "[14]\ttrain-rmse:0.67626\tval-rmse:0.70780\n",
      "[15]\ttrain-rmse:0.63402\tval-rmse:0.66672\n",
      "[16]\ttrain-rmse:0.59690\tval-rmse:0.63062\n",
      "[17]\ttrain-rmse:0.56447\tval-rmse:0.60016\n",
      "[18]\ttrain-rmse:0.53619\tval-rmse:0.57383\n",
      "[19]\ttrain-rmse:0.51138\tval-rmse:0.55044\n",
      "[20]\ttrain-rmse:0.48983\tval-rmse:0.53064\n",
      "[21]\ttrain-rmse:0.47135\tval-rmse:0.51451\n",
      "[22]\ttrain-rmse:0.45501\tval-rmse:0.49998\n",
      "[23]\ttrain-rmse:0.44120\tval-rmse:0.48790\n",
      "[24]\ttrain-rmse:0.42929\tval-rmse:0.47773\n",
      "[25]\ttrain-rmse:0.41881\tval-rmse:0.46891\n",
      "[26]\ttrain-rmse:0.40953\tval-rmse:0.46151\n",
      "[27]\ttrain-rmse:0.40173\tval-rmse:0.45551\n",
      "[28]\ttrain-rmse:0.39470\tval-rmse:0.45043\n",
      "[29]\ttrain-rmse:0.38873\tval-rmse:0.44621\n",
      "[30]\ttrain-rmse:0.38342\tval-rmse:0.44289\n",
      "[31]\ttrain-rmse:0.37876\tval-rmse:0.43989\n",
      "[32]\ttrain-rmse:0.37450\tval-rmse:0.43754\n",
      "[33]\ttrain-rmse:0.37073\tval-rmse:0.43553\n",
      "[34]\ttrain-rmse:0.36743\tval-rmse:0.43390\n",
      "[35]\ttrain-rmse:0.36435\tval-rmse:0.43250\n",
      "[36]\ttrain-rmse:0.36178\tval-rmse:0.43095\n",
      "[37]\ttrain-rmse:0.35927\tval-rmse:0.42976\n",
      "[38]\ttrain-rmse:0.35713\tval-rmse:0.42866\n",
      "[39]\ttrain-rmse:0.35506\tval-rmse:0.42806\n",
      "[40]\ttrain-rmse:0.35343\tval-rmse:0.42746\n",
      "[41]\ttrain-rmse:0.35195\tval-rmse:0.42692\n",
      "[42]\ttrain-rmse:0.35024\tval-rmse:0.42666\n",
      "[43]\ttrain-rmse:0.34862\tval-rmse:0.42616\n",
      "[44]\ttrain-rmse:0.34714\tval-rmse:0.42613\n",
      "[45]\ttrain-rmse:0.34621\tval-rmse:0.42595\n",
      "[46]\ttrain-rmse:0.34477\tval-rmse:0.42563\n",
      "[47]\ttrain-rmse:0.34342\tval-rmse:0.42548\n",
      "[48]\ttrain-rmse:0.34217\tval-rmse:0.42520\n",
      "[49]\ttrain-rmse:0.34097\tval-rmse:0.42513\n",
      "[50]\ttrain-rmse:0.33998\tval-rmse:0.42498\n",
      "[51]\ttrain-rmse:0.33860\tval-rmse:0.42481\n",
      "[52]\ttrain-rmse:0.33767\tval-rmse:0.42453\n",
      "[53]\ttrain-rmse:0.33651\tval-rmse:0.42459\n",
      "[54]\ttrain-rmse:0.33560\tval-rmse:0.42448\n",
      "[55]\ttrain-rmse:0.33480\tval-rmse:0.42449\n",
      "[56]\ttrain-rmse:0.33386\tval-rmse:0.42426\n",
      "[57]\ttrain-rmse:0.33292\tval-rmse:0.42429\n",
      "[58]\ttrain-rmse:0.33196\tval-rmse:0.42438\n",
      "[59]\ttrain-rmse:0.33105\tval-rmse:0.42450\n",
      "[60]\ttrain-rmse:0.33054\tval-rmse:0.42456\n",
      "[61]\ttrain-rmse:0.32953\tval-rmse:0.42444\n",
      "[62]\ttrain-rmse:0.32872\tval-rmse:0.42454\n",
      "[63]\ttrain-rmse:0.32777\tval-rmse:0.42461\n",
      "[64]\ttrain-rmse:0.32673\tval-rmse:0.42479\n",
      "[65]\ttrain-rmse:0.32602\tval-rmse:0.42493\n",
      "[66]\ttrain-rmse:0.32489\tval-rmse:0.42520\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create DMatrix for train and validation\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Create a watchlist\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "# Train the model with eta=0.3\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# Train the model with eta=0.1\n",
    "xgb_params['eta'] = 0.1\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# Compare RMSE for both eta values\n",
    "# The RMSE values will be printed during training in the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d33394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
